# CNN+LSTM+Attention 时间序列预测项目使用指南

## 1. 项目概述

### 1.1 项目功能
本项目是一个基于深度学习的时间序列预测框架，结合了卷积神经网络(CNN)、循环神经网络(RNN)和注意力机制(Attention)的优势，适用于多变量时间序列预测任务。

### 1.2 适用场景
- 电力负荷预测
- 交通流量预测
- 天气数据预测
- 金融时间序列分析
- 工业传感器数据预测
- 其他多变量时间序列预测任务

### 1.3 支持的架构变体

**CNN 特征提取器：**
- `standard`: 标准卷积层
- `depthwise`: 深度可分离卷积
- `dilated`: 空洞卷积
- `tcn`: 时间卷积网络(TCN)

**RNN 序列建模：**
- `lstm`: 长短期记忆网络
- `gru`: 门控循环单元

**注意力机制：**
- `standard`: 标准多头注意力
- `multiscale`: 多尺度注意力

### 1.4 主要特性
- 🔧 **模块化设计**: 支持灵活组合不同架构组件
- 📊 **严格评估**: 确保训练和评估时模型结构完全一致
- 🎯 **批量对比**: 支持多模型批量训练和评估对比
- 📈 **可视化**: 丰富的训练过程和结果可视化
- ⚡ **高性能**: 支持混合精度训练和CUDA加速
- 🛠️ **易配置**: 基于YAML的配置文件系统

## 2. 环境配置

### 2.1 系统要求
- Python 3.8+
- CUDA 11.0+ (GPU训练推荐)
- 内存: 8GB+ (取决于数据集大小)

### 2.2 依赖包安装

```bash
# 基础依赖
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install numpy pandas scikit-learn matplotlib seaborn
pip install pyyaml tensorboard tqdm

# 可选依赖
pip install openpyxl  # Excel文件支持
pip install plotly    # 交互式可视化
```

### 2.3 项目安装

```bash
# 克隆项目
git clone <项目地址>
cd cnnANDlstmANDattention

# 验证安装
python main.py --help
```

### 2.4 GPU环境验证

```python
import torch
print(f"CUDA可用: {torch.cuda.is_available()}")
print(f"CUDA版本: {torch.version.cuda}")
print(f"GPU数量: {torch.cuda.device_count()}")
```

## 3. 数据准备

### 3.1 支持的数据格式
- **CSV**: 推荐格式，支持多种编码
- **NPZ**: NumPy压缩格式
- **NPY**: NumPy数组格式

### 3.2 数据结构要求

**CSV格式示例：**
```csv
timestamp,feature1,feature2,feature3,target1,target2
2023-01-01 00:00:00,1.2,3.4,5.6,7.8,9.0
2023-01-01 01:00:00,1.3,3.5,5.7,7.9,9.1
...
```

**数据要求：**
- 时间序列数据按时间顺序排列
- 数值列应为float类型
- 缺失值会被自动处理(前向填充)
- 建议数据长度 > 1000个时间点

### 3.3 特征和目标列配置

```yaml
data:
  feature_indices: [0, 1, 2, 3, 4]  # 特征列索引，null表示使用所有列
  target_indices: [0, 1, 2]        # 目标列索引，null表示使用所有列
```

### 3.4 数据集划分

```yaml
data:
  train_split: 0.7    # 训练集比例
  val_split: 0.15     # 验证集比例
  # 测试集比例 = 1 - train_split - val_split = 0.15
```

## 4. 配置文件详解

### 4.1 完整配置结构

```yaml
# 设备和输出配置
device: cuda                    # cuda/cpu/auto
output_dir: outputs/experiment  # 输出目录
visual_save_dir: images        # 可视化保存目录
visual_enabled: true           # 是否启用可视化

# 模型配置
model:
  fc_hidden: 128               # 全连接层隐藏单元数
  forecast_horizon: 3          # 预测步长

  # CNN配置
  cnn:
    variant: standard          # standard/depthwise/dilated/tcn
    use_batchnorm: true       # 是否使用批归一化
    dropout: 0.1              # Dropout比例
    layers:                   # 卷积层配置
      - {out_channels: 32, kernel_size: 5, activation: relu}
      - {out_channels: 64, kernel_size: 3, activation: gelu}

  # TCN配置(当cnn.variant=tcn时使用)
  tcn:
    enabled: false
    layers:
      - {out_channels: 32, kernel_size: 3, dilation: 1, activation: relu}
      - {out_channels: 64, kernel_size: 3, dilation: 2, activation: relu}

  # RNN配置
  lstm:
    rnn_type: lstm            # lstm/gru
    hidden_size: 128          # 隐藏状态维度
    num_layers: 2             # RNN层数
    bidirectional: true       # 是否双向
    dropout: 0.1              # RNN层间Dropout

  # 注意力配置
  attention:
    enabled: true             # 是否启用注意力
    variant: standard         # standard/multiscale
    num_heads: 4              # 注意力头数
    dropout: 0.1              # 注意力Dropout
    add_positional_encoding: false  # 是否添加位置编码
    # multiscale专用配置
    multiscale_scales: [1, 2] # 多尺度窗口大小
    multiscale_fuse: sum      # 融合方式: sum/concat

# 数据配置
data:
  data_path: data/your_data.csv    # 数据文件路径
  sequence_length: 64              # 输入序列长度
  horizon: 3                       # 预测步长(通常等于model.forecast_horizon)
  feature_indices: null            # 特征列索引
  target_indices: null             # 目标列索引
  train_split: 0.7                 # 训练集比例
  val_split: 0.15                  # 验证集比例
  normalize: standard              # 归一化方式: standard/minmax/none
  batch_size: 256                  # 批大小
  num_workers: 4                   # 数据加载进程数
  shuffle_train: true              # 是否打乱训练数据
  drop_last: true                  # 是否丢弃最后不完整的批次

# 训练配置
train:
  epochs: 100                      # 训练轮数
  loss: mse                        # 损失函数: mse/mae/huber

  # 优化器配置
  optimizer:
    name: adamw                    # adamw/adam/sgd
    lr: 0.001                      # 学习率
    weight_decay: 0.0001           # 权重衰减

  # 学习率调度器
  scheduler:
    name: cosine                   # cosine/step/plateau/none
    T_max: 100                     # 余弦退火周期
    step_size: 30                  # 步长调度器步长
    gamma: 0.1                     # 学习率衰减因子

  # 早停配置
  early_stopping:
    enabled: true                  # 是否启用早停
    patience: 10                   # 耐心值
    min_delta: 0.0001             # 最小改善阈值

  # 检查点配置
  checkpoints:
    dir: checkpoints              # 检查点保存目录
    save_best_only: true          # 是否只保存最佳模型
    export_best_dir: exports      # 最佳模型导出目录(按架构命名)

  # 其他训练配置
  gradient_clip: 1.0              # 梯度裁剪阈值
  mixed_precision: true           # 是否使用混合精度
  log_dir: runs/experiment        # TensorBoard日志目录
  seed: 42                        # 随机种子
  print_every: 50                 # 打印频率
  deterministic: false            # 是否使用确定性算法
  cudnn_benchmark: true           # 是否启用cuDNN基准测试
  matmul_precision: high          # 矩阵乘法精度
```


## 5. 训练流程

### 5.1 启动训练
```bash
python main.py --config configs/your_exp.yaml
# 可选覆盖输出目录/检查点目录
python main.py --config configs/your_exp.yaml --output_dir outputs/exp1 --ckpt_dir checkpoints/exp1
```

### 5.2 日志输出解读
- Step日志：`Epoch E Step I: train_loss=...`
- Epoch汇总：`Epoch E: train_loss=..., val_loss=..., test_loss=...`
- TensorBoard：日志位于 `train.log_dir`，启动方式：
```bash
tensorboard --logdir runs/experiment --port 6006
```

### 5.3 检查点保存与恢复
- 自动保存：每个 epoch 结束保存快照（或仅保存最优），最终保存 `model_last.pt`
- 最优模型：`model_best.pt`；若设置了 `export_best_dir`，会额外按架构首字母命名导出，例如：
  - standard CNN + GRU + standard attention -> `sgs.pt`
- 恢复训练：
```bash
python main.py --config configs/your_exp.yaml --resume checkpoints/exp1/model_last.pt
```

### 5.4 可视化输出
- 训练/验证/测试损失曲线：`loss_curve.png`, `loss_curve_log.png`
- 学习率曲线：`lr_curve.png`
- 预测对比图、注意力热力图等会输出到 `visual_save_dir`

## 6. 评估与测试

### 6.1 单模型评估
```bash
python standalone_eval.py \
  --checkpoint checkpoints/exp1/model_best.pt \
  --data data/your_data.csv \
  --output_dir results/eval_best \
  --sequence_length 64 --horizon 3 --normalize standard
```

### 6.2 批量评估对比
```bash
python batch_eval.py \
  --checkpoints_dir checkpoints/ \
  --data data/your_data.csv \
  --output_dir results/batch_eval \
  --save_summary_plot --debug
```
输出：
- `batch_metrics.csv`: 每个模型的 MSE/MAE/RMSE/MAPE/R2 等指标
- `metrics_summary_mse.png`: MSE对比柱状图

### 6.3 评估指标
- MSE/MAE/RMSE/MAPE：越小越好
- R2：越接近1越好

### 6.4 结果可视化
- 可用 `tools/merge_and_visualize.py` 对不同数据集/多模型进行综合对比（参考脚本说明）

## 7. 常见问题与故障排除

### 7.1 配置错误
- 报 `缺少必需字段`：检查 YAML 中对应模块是否缺失字段（例如 TCN 的 dilation 必须显式）
- 字段类型不符：确保整数/浮点/布尔/列表类型正确（如 multiscale_scales 为整数列表）

### 7.2 CUDA/显存问题
- OOM：减小 batch_size、sequence_length、模型宽度（out_channels/hidden_size）
- 指定 GPU：在配置中设置 `device: cuda` 并导出 `CUDA_VISIBLE_DEVICES`
- AMP异常：关闭 `train.mixed_precision` 或升级 PyTorch

### 7.3 模型加载失败（严格评估）
- 报 `输入特征数与训练时不一致`：对齐 `feature_indices` 或使用训练数据
- 报 `输出维度不一致`：确保 `forecast_horizon × 目标列数 == 头部维度`
- 若不记得目标列，可设置环境变量尝试自动对齐：
```bash
EVAL_AUTO_ALIGN_TARGETS=1 EVAL_AUTO_INFER_HZ=1 \
python batch_eval.py --checkpoints_dir checkpoints --data data/your.csv --output_dir results
```
若仍失败，请显式提供训练时的 `target_indices`。

## 8. 高级功能

### 8.1 严格评估模式
- 默认开启（环境变量 `EVAL_STRICT=1`），严格校验：
  - 输入通道=特征数一致
  - 输出维度= horizon×目标数 一致
  - 权重 strict=True 加载
- 目的：确保评估结构与训练完全一致，指标可比

### 8.2 自定义架构
- 修改 `model.cnn.variant`、`model.tcn.enabled` 及其 `layers` 列表
- `dilated` 必须显式提供每层 `dilation_rates`
- `tcn` 必须为每层显式提供 `dilation`、`out_channels`、`kernel_size`、`activation`
- 注意力 `multiscale` 需提供 `multiscale_scales` 与 `multiscale_fuse`

### 8.3 超参数调优建议
- 搜索范围：
  - CNN通道数：32~256，层数 2~5
  - TCN膨胀：1/2/4/8...
  - RNN隐藏维度：128~512，层数 1~3
  - 注意力头数：4/8，dropout：0.0~0.2
  - 学习率：1e-4 ~ 3e-3，权重衰减：1e-6 ~ 1e-3
- 策略：网格/贝叶斯优化；固定随机种子确保可比性

---
如需进一步的模板或脚本（例如跨数据集汇总对比可视化），请参考 tools/merge_and_visualize.py，或告知我你的实际表头字段以便微调脚本映射。
